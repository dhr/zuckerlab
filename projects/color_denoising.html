<!DOCTYPE html><html><head><meta charset="utf8"><meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1"><meta name="description" content="description of your site"><meta name="author" content="author of the site"><title>Research &gt; Color Denoising | Zucker Computational Vision Group</title><link rel="stylesheet" href="//fonts.googleapis.com/css?family=Open+Sans:300"><link rel="stylesheet" href="//fonts.googleapis.com/css?family=Rosario:400,400italic,700"><link rel="stylesheet" href="/styles/style.6247f7ac.css"><body><div id="wrapper"><nav id="main-nav"><ul><li><h1><a href="/">Zucker<span class="lab">lab</span></a></h1></li><li><a href="/">Research</a></li><li><a href="/people.html">People</a></li><li><a href="/publications.html">Publications</a></li><li><a href="/bio.html">About Steve</a></li><li><a href="/contact.html">Contact</a></li></ul><div id="sidecontent"></div></nav><div id="content"><h1>Research<span class="subtitle">Color Denoising</span></h1><p class="details">The denoising of color images is an increasingly studied problem whose state-of-the-art solutions employ a variety of diffusion schemes. Specifying the correct diffusion is difficult, however, in part because of the subtleties of color interactions. We address this difficulty by proposing a perceptual organization approach to color denoising based on the principle of good continuation. We exploit the periodic chromatic (hue) component of the color in its representation as a frame field. We derive two hue curvatures and use them to construct a local model for the behavior of the color, which in turn specifies consistency constraints between nearby color measurements. These constraints are then used to replace noisy pixels by examining their spatial context. Such a contextual analysis (combined with standard methods to handle the scalar channels, saturation and lightness), results in a robust noise removal process that preserves discontinuities, singularities, and fine chromatic structures, including those that diffusion processes are prone to distort. We demonstrate our approach on a variety of synthetic and natural images.</p><div class="demo-imgs"><img src="/img/demo/color-demo-noisy.bf7b69d8.gif"><img src="/img/demo/color-demo-default.f0914b7e.gif"></div></div></div><script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>